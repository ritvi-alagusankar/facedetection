{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!kaggle datasets download -d iamtushara/face-detection-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip uninstall opencv-python\n",
    "pip install opencv-contrib-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image # Pillow library for easier image handling\n",
    "import pickle # To save the name mapping\n",
    "\n",
    "# Path to the dataset containing subfolders for each person\n",
    "dataset_path = 'dataset/friends'\n",
    "# Path where the trained model will be saved\n",
    "trainer_path = 'trainer'\n",
    "model_file = os.path.join(trainer_path, 'lbph_model.yml')\n",
    "label_map_file = os.path.join(trainer_path, 'labels.pickle')\n",
    "\n",
    "# Ensure the trainer directory exists\n",
    "if not os.path.exists(trainer_path):\n",
    "    os.makedirs(trainer_path)\n",
    "\n",
    "# We'll use a Haar Cascade classifier to detect faces within the training images\n",
    "# This ensures LBPH is trained only on face regions\n",
    "face_detector = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "# Initialize LBPH face recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "def get_images_and_labels(dataset_path):\n",
    "    \"\"\"\n",
    "    Reads images from the dataset, detects faces, and prepares lists of\n",
    "    face samples and corresponding integer labels.\n",
    "    \"\"\"\n",
    "    image_paths = []\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        for file in files:\n",
    "            if file.endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                path = os.path.join(root, file)\n",
    "                image_paths.append(path)\n",
    "\n",
    "    face_samples = []\n",
    "    ids = []\n",
    "    label_ids = {} # Dictionary to map person names to integer labels\n",
    "    current_id = 0\n",
    "\n",
    "    print(\"Preparing training data...\")\n",
    "    for image_path in image_paths:\n",
    "        # Get the person's name from the directory structure\n",
    "        label_name = os.path.basename(os.path.dirname(image_path))\n",
    "        # print(f\"Processing {label_name}: {os.path.basename(image_path)}\") # Debugging\n",
    "\n",
    "        # Assign an integer ID if this is a new person\n",
    "        if label_name not in label_ids:\n",
    "            label_ids[label_name] = current_id\n",
    "            current_id += 1\n",
    "        person_id = label_ids[label_name]\n",
    "\n",
    "        try:\n",
    "            # Open image using Pillow (handles various formats, converts to grayscale)\n",
    "            pil_image = Image.open(image_path).convert('L') # Convert to grayscale\n",
    "            image_np = np.array(pil_image, 'uint8')\n",
    "\n",
    "            # Detect faces in the training image\n",
    "            faces = face_detector.detectMultiScale(image_np, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "            for (x, y, w, h) in faces:\n",
    "                # Extract the face ROI (Region of Interest)\n",
    "                face_roi = image_np[y:y+h, x:x+w]\n",
    "                face_samples.append(face_roi)\n",
    "                ids.append(person_id)\n",
    "                # Optional: Display face being processed\n",
    "                # cv2.imshow(\"Training\", face_roi)\n",
    "                # cv2.waitKey(1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "    # cv2.destroyAllWindows() # Close display window if used\n",
    "    print(f\"\\nFound {len(face_samples)} face samples for training.\")\n",
    "    print(f\"Label map created: {label_ids}\")\n",
    "\n",
    "    # Save the label map (name -> id)\n",
    "    with open(label_map_file, 'wb') as f:\n",
    "        pickle.dump(label_ids, f)\n",
    "    print(f\"Label map saved to {label_map_file}\")\n",
    "\n",
    "    return face_samples, np.array(ids)\n",
    "\n",
    "# --- Main Training Execution ---\n",
    "faces, ids = get_images_and_labels(dataset_path)\n",
    "\n",
    "if not faces:\n",
    "    print(\"No faces found in the dataset. Please check dataset structure and images.\")\n",
    "else:\n",
    "    print(\"\\nTraining LBPH model...\")\n",
    "    recognizer.train(faces, ids)\n",
    "    recognizer.write(model_file) # Save the trained model\n",
    "    print(f\"LBPH model trained and saved to {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# --- Configuration ---\n",
    "cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'\n",
    "recognizer_model_path = 'trainer/lbph_model.yml'\n",
    "label_map_path = 'trainer/labels.pickle'\n",
    "recognition_confidence_threshold = 70 # Adjust based on testing (lower value means stricter match)\n",
    "\n",
    "# --- Load Models and Data ---\n",
    "# Load Haar Cascade for face detection\n",
    "face_detector = cv2.CascadeClassifier(cascade_path)\n",
    "if face_detector.empty():\n",
    "    print(f\"Error loading Haar Cascade from {cascade_path}\")\n",
    "    exit()\n",
    "print(\"Haar Cascade face detector loaded.\")\n",
    "\n",
    "# Load the trained LBPH recognizer\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "if not os.path.exists(recognizer_model_path):\n",
    "    print(f\"Error: Trained model not found at {recognizer_model_path}\")\n",
    "    print(\"Please run the train_lbph.py script first.\")\n",
    "    exit()\n",
    "recognizer.read(recognizer_model_path)\n",
    "print(f\"LBPH recognizer model loaded from {recognizer_model_path}\")\n",
    "\n",
    "# Load the label map (name -> id) and invert it (id -> name)\n",
    "if not os.path.exists(label_map_path):\n",
    "    print(f\"Error: Label map not found at {label_map_path}\")\n",
    "    print(\"Please run the train_lbph.py script first.\")\n",
    "    exit()\n",
    "with open(label_map_path, 'rb') as f:\n",
    "    og_label_ids = pickle.load(f)\n",
    "    # Invert the dictionary to map id -> name\n",
    "    id_to_name = {v: k for k, v in og_label_ids.items()}\n",
    "print(f\"Label map loaded: {id_to_name}\")\n",
    "\n",
    "\n",
    "# --- Initialize Webcam ---\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open webcam.\")\n",
    "    exit()\n",
    "\n",
    "print(\"\\nStarting real-time detection and recognition...\")\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Failed to capture frame.\")\n",
    "        break\n",
    "\n",
    "    # Convert to grayscale for detection and recognition\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect faces using Haar Cascade\n",
    "    faces = face_detector.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.1,      # How much the image size is reduced at each image scale\n",
    "        minNeighbors=5,       # How many neighbors each candidate rectangle should have to retain it\n",
    "        minSize=(40, 40)      # Minimum possible object size. Objects smaller than this are ignored\n",
    "    )\n",
    "\n",
    "    # Process each detected face\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Extract the face ROI (Region of Interest) in grayscale\n",
    "        face_roi_gray = gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Perform recognition using the trained LBPH model\n",
    "        id_, confidence = recognizer.predict(face_roi_gray)\n",
    "\n",
    "        # Default name if confidence is too low\n",
    "        name = \"Unknown\"\n",
    "        display_color = (0, 0, 255) # Red for Unknown\n",
    "\n",
    "        # Check if the confidence is below the threshold (lower score is better in LBPH)\n",
    "        # LBPH confidence is distance, 0 is perfect match.\n",
    "        if confidence < recognition_confidence_threshold:\n",
    "            if id_ in id_to_name:\n",
    "                name = id_to_name[id_]\n",
    "                display_color = (0, 255, 0) # Green for known\n",
    "            else:\n",
    "                # This case should ideally not happen if label map is correct\n",
    "                print(f\"Warning: Recognized ID {id_} not found in label map.\")\n",
    "                name = f\"ID {id_}?\" # Display the ID if name is missing\n",
    "\n",
    "            display_text = f\"{name} ({confidence:.2f})\"\n",
    "        else:\n",
    "            # Confidence is too high (meaning poor match)\n",
    "             display_text = f\"Unknown ({confidence:.2f})\"\n",
    "\n",
    "\n",
    "        # --- Draw bounding box and text on the original color frame ---\n",
    "        # Draw rectangle around the face\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), display_color, 2)\n",
    "\n",
    "        # Put text (Name and Confidence) above the rectangle\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        text_y = y - 10 if y - 10 > 10 else y + 10 # Position text above box, avoid going off-screen\n",
    "        cv2.putText(frame, display_text, (x, text_y), font, 0.6, display_color, 2)\n",
    "\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Real-Time Face Detection and Recognition', frame)\n",
    "\n",
    "    # Break the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# --- Cleanup ---\n",
    "print(\"Releasing resources...\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
