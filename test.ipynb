{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/content/face_dataset/merged/labels/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m hog_detector \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Pre-load label filenames into a dictionary for fast lookup\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m label_files \u001b[38;5;241m=\u001b[39m {os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(f)[\u001b[38;5;241m0\u001b[39m]: f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(labels_path)}\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Iterate over all image files\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_name \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(dataset_path):\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/content/face_dataset/merged/labels/train'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset paths\n",
    "dataset_path = \"/content/face_dataset/merged/images/train\"\n",
    "labels_path = \"/content/face_dataset/merged/labels/train\"\n",
    "\n",
    "# Process a smaller subset first\n",
    "MAX_IMAGES = 100  # Change as needed\n",
    "image_count = 0  # Counter for processed images\n",
    "\n",
    "face_size = (64, 64)\n",
    "faces = []\n",
    "labels = []\n",
    "detected_images_list = []  # Store images with bounding boxes for visualization\n",
    "missing_labels = 0\n",
    "\n",
    "# Load HOG + SVM-based face detector from dlib\n",
    "hog_detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Pre-load label filenames into a dictionary for fast lookup\n",
    "label_files = {os.path.splitext(f)[0]: f for f in os.listdir(labels_path)}\n",
    "\n",
    "# Iterate over all image files\n",
    "for image_name in os.listdir(dataset_path):\n",
    "    if image_count >= MAX_IMAGES:\n",
    "        break  # Stop processing after reaching MAX_IMAGES\n",
    "    image_count += 1\n",
    "\n",
    "    image_path = os.path.join(dataset_path, image_name)\n",
    "\n",
    "    # Read image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        print(f\"Skipping unreadable image: {image_path}\")\n",
    "        continue\n",
    "\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.equalizeHist(gray)  # Improves contrast\n",
    "\n",
    "    # Detect faces using HOG + SVM\n",
    "    detected_faces = hog_detector(gray)\n",
    "\n",
    "    if len(detected_faces) == 0:\n",
    "        continue  # Skip images with no faces\n",
    "\n",
    "    # Draw bounding boxes\n",
    "    for face in detected_faces:\n",
    "        x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Green box around detected face\n",
    "\n",
    "    # Store the image with bounding boxes\n",
    "    detected_images_list.append(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))  # Convert for Matplotlib display\n",
    "\n",
    "    # Match labels faster\n",
    "    base_name = os.path.splitext(image_name)[0]  # Remove file extension\n",
    "    label_filename = label_files.get(base_name, None)  # Find label file\n",
    "\n",
    "    if label_filename:\n",
    "        label_path = os.path.join(labels_path, label_filename)\n",
    "        with open(label_path, \"r\") as label_file:\n",
    "            label = label_file.read().strip()\n",
    "            labels.append(label)\n",
    "    else:\n",
    "        missing_labels += 1\n",
    "        labels.append(\"Unknown\")\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "faces = np.array(faces)\n",
    "labels = np.array(labels)\n",
    "\n",
    "print(f\"Total faces detected: {len(detected_images_list)}\")\n",
    "print(f\"Total missing labels: {missing_labels}\")  # Print at the end\n",
    "\n",
    "# ðŸ“Œ Display multiple images in 2-3 rows with bounding boxes\n",
    "num_images_to_display = min(9, len(detected_images_list))  # Display up to 9 images\n",
    "rows = 3\n",
    "cols = num_images_to_display // rows if num_images_to_display % rows == 0 else (num_images_to_display // rows) + 1\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 10))\n",
    "\n",
    "# Flatten the axes array for easier indexing\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i in range(num_images_to_display):\n",
    "    axes[i].imshow(detected_images_list[i])  # Show image with bounding box\n",
    "    axes[i].axis(\"off\")\n",
    "    axes[i].set_title(f\"Image {i+1}\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preparing training data from: png_dataset/png_dataset\n",
      "[INFO] Processing images for: amisha\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-001.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-003.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-013.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-015.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-023.png. Skipping.\n",
      "[WARNING] Invalid face bounds detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-051.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-053.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-055.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-057.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-059.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-077.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-079.png. Skipping.\n",
      "[INFO] Processing images for: dhanoosh\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-060.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-064.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-092.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-096.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-100.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-104.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-124.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-128.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-132.png. Skipping.\n",
      "[INFO] Processing images for: jose\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-006.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-007.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-013.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-014.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-015.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-017.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-018.png. Skipping.\n",
      "[WARNING] Invalid face bounds detected in: png_dataset/png_dataset\\jose\\ezgif-frame-041.png. Skipping.\n",
      "[WARNING] Invalid face bounds detected in: png_dataset/png_dataset\\jose\\ezgif-frame-042.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\IMG-20250331-WA0039.png. Skipping.\n",
      "[INFO] Processing images for: jui\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-009.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-011.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-013.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-015.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-017.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-020.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-022.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-025.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-034.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-039.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-041.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-043.png. Skipping.\n",
      "[INFO] Processing images for: ritvi\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-014.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-015.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-016.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-017.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-018.png. Skipping.\n",
      "[INFO] Processing images for: siddhangana\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-001.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-003.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-005.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-007.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-023.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-025.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-027.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-029.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-041.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-043.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-045.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-059.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-061.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-063.png. Skipping.\n",
      "[INFO] Processing images for: sparsh\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-010.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-030.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-035.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-060.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-061.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-062.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-068.png. Skipping.\n",
      "[WARNING] Invalid face bounds detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-069.png. Skipping.\n",
      "[INFO] Processing images for: yash\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-010.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-011.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-012.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-013.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-014.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-015.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-016.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-017.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-040.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-041.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-042.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-043.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-044.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-045.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-046.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-047.png. Skipping.\n",
      "[INFO] Total faces prepared for training: 234\n",
      "[INFO] Total unique persons (labels): 8\n",
      "[INFO] Training LBPH model...\n",
      "[INFO] LBPH model trained successfully.\n",
      "[INFO] Starting video stream...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 240\u001b[0m\n\u001b[0;32m    238\u001b[0m      \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[INFO] Please set the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset_path\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m variable correctly.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m train_model(dataset_path): \u001b[38;5;66;03m# Train the model first\u001b[39;00m\n\u001b[1;32m--> 240\u001b[0m     run_live_recognition() \u001b[38;5;66;03m# If training is successful, run live recognition\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[ERROR] Model training failed. Cannot proceed to live recognition.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[4], line 225\u001b[0m, in \u001b[0;36mrun_live_recognition\u001b[1;34m()\u001b[0m\n\u001b[0;32m    222\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLive Face Recognition (Press \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to quit)\u001b[39m\u001b[38;5;124m\"\u001b[39m, frame)\n\u001b[0;32m    224\u001b[0m     \u001b[38;5;66;03m# Check for exit key ('q')\u001b[39;00m\n\u001b[1;32m--> 225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m0xFF\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# --- Cleanup ---\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import time # For FPS calculation (optional)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Main dataset folder containing subfolders named after people\n",
    "# Example structure:\n",
    "# /path/to/your/dataset/\n",
    "#  |- Person_A/\n",
    "#  |  |- img1.jpg\n",
    "#  |  |- img2.png\n",
    "#  |- Person_B/\n",
    "#  |  |- pic1.jpeg\n",
    "# ...\n",
    "dataset_path = \"png_dataset/png_dataset\" \n",
    "\n",
    "# Size to resize cropped faces to (consistency is key for LBPH)\n",
    "face_size = (100, 100)\n",
    "\n",
    "# LBPH Confidence threshold (lower values mean higher confidence)\n",
    "# Adjust this based on testing - might need values between 50 and 100\n",
    "confidence_threshold = 50\n",
    "\n",
    "# --- Global Variables ---\n",
    "# Load Dlib's pre-trained frontal face detector (HOG-based)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Create LBPH Face Recognizer\n",
    "# Note: You might need to install opencv-contrib-python\n",
    "# pip install opencv-contrib-python\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Dictionary to map numerical labels to names\n",
    "label_to_name = {}\n",
    "\n",
    "# --- Function to Prepare Training Data and Train LBPH ---\n",
    "def train_model(data_folder_path):\n",
    "    \"\"\"\n",
    "    Scans the dataset folder, detects faces, prepares training data,\n",
    "    and trains the LBPH recognizer.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Preparing training data from: {data_folder_path}\")\n",
    "    faces = []\n",
    "    labels = []\n",
    "    current_label_id = 0\n",
    "    global label_to_name # Allow modification of the global dictionary\n",
    "\n",
    "    # Iterate through each person's folder in the dataset path\n",
    "    for person_name in os.listdir(data_folder_path):\n",
    "        person_folder_path = os.path.join(data_folder_path, person_name)\n",
    "\n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(person_folder_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"[INFO] Processing images for: {person_name}\")\n",
    "        # Assign a numerical label to this person if not already done\n",
    "        if person_name not in label_to_name.values():\n",
    "            label_to_name[current_label_id] = person_name\n",
    "            person_label = current_label_id\n",
    "            current_label_id += 1\n",
    "        else:\n",
    "            # Find existing label ID if name already exists (shouldn't happen with unique folder names)\n",
    "            person_label = [id for id, name in label_to_name.items() if name == person_name][0]\n",
    "\n",
    "\n",
    "        # Iterate through images in the person's folder\n",
    "        for image_name in os.listdir(person_folder_path):\n",
    "            image_path = os.path.join(person_folder_path, image_name)\n",
    "\n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"[WARNING] Could not read image: {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Convert to grayscale (Dlib detector and LBPH work better with grayscale)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # Optional: Histogram Equalization can sometimes improve detection/recognition\n",
    "            # gray = cv2.equalizeHist(gray)\n",
    "\n",
    "            # Detect faces using Dlib detector\n",
    "            # The '1' indicates upsampling the image 1 time, making it larger\n",
    "            # and potentially detecting more faces, but it's slower. Use 0 for faster.\n",
    "            detected_faces = detector(gray, 1)\n",
    "\n",
    "            if len(detected_faces) == 0:\n",
    "                print(f\"[WARNING] No face detected in: {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Process only the first detected face for simplicity in training\n",
    "            face_rect = detected_faces[0]\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "\n",
    "            # Ensure coordinates are valid\n",
    "            if x < 0 or y < 0 or w <= 0 or h <= 0:\n",
    "                print(f\"[WARNING] Invalid face bounds detected in: {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Crop the face region from the grayscale image\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "            # Check if cropping resulted in an empty image\n",
    "            if face_roi.size == 0:\n",
    "                 print(f\"[WARNING] Empty face ROI after cropping in: {image_path}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            # Resize the face ROI to the standard size\n",
    "            resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Append the processed face and its corresponding label\n",
    "            faces.append(resized_face)\n",
    "            labels.append(person_label)\n",
    "\n",
    "    if not faces:\n",
    "        print(\"[ERROR] No faces found for training. Check dataset path and image content.\")\n",
    "        return False\n",
    "\n",
    "    print(f\"[INFO] Total faces prepared for training: {len(faces)}\")\n",
    "    print(f\"[INFO] Total unique persons (labels): {len(label_to_name)}\")\n",
    "    print(\"[INFO] Training LBPH model...\")\n",
    "\n",
    "    # Train the recognizer\n",
    "    # Ensure labels is a NumPy array of type int32\n",
    "    recognizer.train(faces, np.array(labels, dtype=np.int32))\n",
    "\n",
    "    print(\"[INFO] LBPH model trained successfully.\")\n",
    "    # Optional: Save the trained model and label mapping for later use\n",
    "    # recognizer.save(\"lbph_model.yml\")\n",
    "    # with open(\"label_map.txt\", \"w\") as f:\n",
    "    #    for label_id, name in label_to_name.items():\n",
    "    #        f.write(f\"{label_id}:{name}\\n\")\n",
    "    # print(\"[INFO] Model and label map saved.\")\n",
    "    return True\n",
    "\n",
    "# --- Function for Live Face Recognition ---\n",
    "def run_live_recognition():\n",
    "    \"\"\"\n",
    "    Opens the camera, detects faces, and performs recognition using the trained model.\n",
    "    \"\"\"\n",
    "    global label_to_name # Access the global mapping\n",
    "\n",
    "    print(\"[INFO] Starting video stream...\")\n",
    "    # Use 0 for default camera, or change if you have multiple cameras\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    time.sleep(1.0) # Allow camera sensor to warm up\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"[ERROR] Cannot open camera. Exiting.\")\n",
    "        return\n",
    "\n",
    "    prev_time = 0\n",
    "\n",
    "    while True:\n",
    "        # Read frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"[ERROR] Failed to grab frame. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # For FPS calculation\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_time)\n",
    "        prev_time = current_time\n",
    "\n",
    "        # Convert frame to grayscale for detection\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Optional: Equalize histogram\n",
    "        # gray_frame = cv2.equalizeHist(gray_frame)\n",
    "\n",
    "        # Detect faces in the current frame\n",
    "        detected_faces = detector(gray_frame, 0) # Use 0 for speed in live feed\n",
    "\n",
    "        # Loop over detected faces\n",
    "        for face_rect in detected_faces:\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "\n",
    "            # Ensure coordinates are valid and within frame boundaries\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            w = min(w, frame.shape[1] - x)\n",
    "            h = min(h, frame.shape[0] - y)\n",
    "\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue # Skip invalid detections\n",
    "\n",
    "            # Crop the face region *from the grayscale frame* for recognition\n",
    "            face_roi = gray_frame[y:y+h, x:x+w]\n",
    "\n",
    "             # Check if cropping resulted in an empty image\n",
    "            if face_roi.size == 0:\n",
    "                 continue\n",
    "\n",
    "            # Resize the cropped face to the standard size used for training\n",
    "            resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "\n",
    "            # Perform prediction using the trained LBPH recognizer\n",
    "            label_id, confidence = recognizer.predict(resized_face)\n",
    "\n",
    "            # Get the name associated with the predicted label ID\n",
    "            # Use \"Unknown\" if confidence is too high (poor match) or label unknown\n",
    "            if confidence > confidence_threshold and label_id in label_to_name:\n",
    "                name = label_to_name[label_id]\n",
    "                display_text = f\"{name} ({confidence:.2f})\"\n",
    "            else:\n",
    "                name = \"Unknown\"\n",
    "                display_text = f\"{name} ({confidence:.2f})\" # Still show confidence for unknowns\n",
    "\n",
    "            # Draw bounding box around the face on the *original color* frame\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Put the predicted name (and confidence) text above the bounding box\n",
    "            text_y = y - 10 if y - 10 > 10 else y + 10 # Position text above box\n",
    "            cv2.putText(frame, display_text, (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Display FPS on frame (optional)\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Show the resulting frame\n",
    "        cv2.imshow(\"Live Face Recognition (Press 'q' to quit)\", frame)\n",
    "\n",
    "        # Check for exit key ('q')\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    print(\"[INFO] Stopping video stream and cleaning up...\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] Application finished.\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.isdir(dataset_path):\n",
    "         print(f\"[ERROR] Dataset path not found or is not a directory: {dataset_path}\")\n",
    "         print(\"[INFO] Please set the 'dataset_path' variable correctly.\")\n",
    "    elif train_model(dataset_path): # Train the model first\n",
    "        run_live_recognition() # If training is successful, run live recognition\n",
    "    else:\n",
    "        print(\"[ERROR] Model training failed. Cannot proceed to live recognition.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Preparing training data from: png_dataset/png_dataset\n",
      "[INFO] Processing images for: amisha\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-001.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-003.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-013.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-015.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-023.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-053.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-055.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-057.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-059.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-077.png for amisha. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\amisha\\ezgif-frame-079.png for amisha. Skipping.\n",
      "[INFO] Added 29 face images for amisha.\n",
      "[INFO] Processing images for: dhanoosh\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-060.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-064.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-092.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-096.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-100.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-104.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-124.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-128.png for dhanoosh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\dhanoosh\\ezgif-frame-132.png for dhanoosh. Skipping.\n",
      "[INFO] Added 31 face images for dhanoosh.\n",
      "[INFO] Processing images for: jose\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-006.png for jose. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-007.png for jose. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-013.png for jose. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-014.png for jose. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-015.png for jose. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-017.png for jose. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\ezgif-frame-018.png for jose. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jose\\IMG-20250331-WA0039.png for jose. Skipping.\n",
      "[INFO] Added 32 face images for jose.\n",
      "[INFO] Processing images for: jui\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-009.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-011.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-013.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-015.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-017.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-020.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-022.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-025.png for jui. Skipping.\n",
      "[WARNING] Invalid face bounds detected or calculated in: png_dataset/png_dataset\\jui\\ezgif-frame-032.png. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-034.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-039.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-041.png for jui. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\jui\\ezgif-frame-043.png for jui. Skipping.\n",
      "[INFO] Added 27 face images for jui.\n",
      "[INFO] Processing images for: ritvi\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-014.png for ritvi. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-015.png for ritvi. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-016.png for ritvi. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-017.png for ritvi. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\ritvi\\ezgif-frame-018.png for ritvi. Skipping.\n",
      "[INFO] Added 35 face images for ritvi.\n",
      "[INFO] Processing images for: siddhangana\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-001.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-003.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-005.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-007.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-023.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-025.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-027.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-029.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-041.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-043.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-045.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-059.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-061.png for siddhangana. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\siddhangana\\ezgif-frame-063.png for siddhangana. Skipping.\n",
      "[INFO] Added 26 face images for siddhangana.\n",
      "[INFO] Processing images for: sparsh\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-010.png for sparsh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-030.png for sparsh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-035.png for sparsh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-060.png for sparsh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-061.png for sparsh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-062.png for sparsh. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\sparsh\\ezgif-frame-068.png for sparsh. Skipping.\n",
      "[WARNING] Multiple faces (2) detected in: png_dataset/png_dataset\\sparsh\\IMG20221014172707.png for sparsh. Using the first one.\n",
      "[WARNING] Multiple faces (2) detected in: png_dataset/png_dataset\\sparsh\\IMG20231006105913.png for sparsh. Using the first one.\n",
      "[WARNING] Invalid face bounds detected or calculated in: png_dataset/png_dataset\\sparsh\\IMG20231006105923.png. Skipping.\n",
      "[WARNING] Multiple faces (2) detected in: png_dataset/png_dataset\\sparsh\\photo_1_2025-03-06_14-37-02.png for sparsh. Using the first one.\n",
      "[INFO] Added 32 face images for sparsh.\n",
      "[INFO] Processing images for: yash\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-010.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-011.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-012.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-013.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-014.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-015.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-016.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-017.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-040.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-041.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-042.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-043.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-044.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-045.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-046.png for yash. Skipping.\n",
      "[WARNING] No face detected in: png_dataset/png_dataset\\yash\\ezgif-frame-047.png for yash. Skipping.\n",
      "[INFO] Added 24 face images for yash.\n",
      "\n",
      "[INFO] Total faces prepared for training: 236\n",
      "[INFO] Total unique persons (labels): 8\n",
      "[INFO] Label map: {0: 'amisha', 1: 'dhanoosh', 2: 'jose', 3: 'jui', 4: 'ritvi', 5: 'siddhangana', 6: 'sparsh', 7: 'yash'}\n",
      "[INFO] Training LBPH model...\n",
      "[INFO] LBPH model trained successfully.\n",
      "\n",
      "==============================\n",
      "[INFO] Starting model testing on the dataset...\n",
      "==============================\n",
      "[TESTING] Evaluating images for: amisha (Expected Label: 0)\n",
      "[TESTING] Finished amisha: Found faces in 29/40 images. Correctly recognized: 29/29\n",
      "[TESTING] Evaluating images for: dhanoosh (Expected Label: 1)\n",
      "[TESTING] Finished dhanoosh: Found faces in 31/40 images. Correctly recognized: 31/31\n",
      "[TESTING] Evaluating images for: jose (Expected Label: 2)\n",
      "[TESTING] Finished jose: Found faces in 32/40 images. Correctly recognized: 32/32\n",
      "[TESTING] Evaluating images for: jui (Expected Label: 3)\n",
      "[TESTING] Finished jui: Found faces in 28/40 images. Correctly recognized: 27/28\n",
      "[TESTING] Evaluating images for: ritvi (Expected Label: 4)\n",
      "[TESTING] Finished ritvi: Found faces in 35/40 images. Correctly recognized: 35/35\n",
      "[TESTING] Evaluating images for: siddhangana (Expected Label: 5)\n",
      "[TESTING] Finished siddhangana: Found faces in 26/40 images. Correctly recognized: 26/26\n",
      "[TESTING] Evaluating images for: sparsh (Expected Label: 6)\n",
      "[TESTING] Finished sparsh: Found faces in 33/40 images. Correctly recognized: 32/33\n",
      "[TESTING] Evaluating images for: yash (Expected Label: 7)\n",
      "[TESTING] Finished yash: Found faces in 24/40 images. Correctly recognized: 24/24\n",
      "\n",
      "==============================\n",
      "[INFO] Dataset Testing Summary\n",
      "==============================\n",
      "Total faces detected across all tested images: 238\n",
      "Total detected faces subjected to recognition: 236\n",
      "Total correct recognitions (within threshold): 236\n",
      "Recognition Success Rate: 100.00%\n",
      "==============================\n",
      "\n",
      "[INFO] Starting video stream for live recognition...\n",
      "[ERROR] Failed to grab frame. Exiting.\n",
      "[INFO] Stopping video stream and cleaning up...\n",
      "[INFO] Application finished.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import time # For FPS calculation (optional)\n",
    "\n",
    "# --- Configuration ---\n",
    "# Main dataset folder containing subfolders named after people\n",
    "# Example structure:\n",
    "# /path/to/your/dataset/\n",
    "#  |- Person_A/\n",
    "#  |  |- img1.jpg\n",
    "#  |  |- img2.png\n",
    "#  |- Person_B/\n",
    "#  |  |- pic1.jpeg\n",
    "# ...\n",
    "dataset_path = \"png_dataset/png_dataset\"\n",
    "\n",
    "# Size to resize cropped faces to (consistency is key for LBPH)\n",
    "face_size = (100, 100)\n",
    "\n",
    "# LBPH Confidence threshold (lower values mean higher confidence)\n",
    "# Adjust this based on testing - might need values between 50 and 100\n",
    "confidence_threshold = 85 # Adjusted slightly for potentially better testing results\n",
    "\n",
    "# --- NEW: Testing Configuration ---\n",
    "# Set to True to test the model on the dataset after training\n",
    "activate_test = True\n",
    "\n",
    "# --- Global Variables ---\n",
    "# Load Dlib's pre-trained frontal face detector (HOG-based)\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Create LBPH Face Recognizer\n",
    "# Note: You might need to install opencv-contrib-python\n",
    "# pip install opencv-contrib-python\n",
    "recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "# Dictionary to map numerical labels to names\n",
    "label_to_name = {}\n",
    "\n",
    "# --- Function to Prepare Training Data and Train LBPH ---\n",
    "def train_model(data_folder_path):\n",
    "    \"\"\"\n",
    "    Scans the dataset folder, detects faces, prepares training data,\n",
    "    and trains the LBPH recognizer.\n",
    "    Returns True if training was successful, False otherwise.\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Preparing training data from: {data_folder_path}\")\n",
    "    faces = []\n",
    "    labels = []\n",
    "    current_label_id = 0\n",
    "    global label_to_name # Allow modification of the global dictionary\n",
    "    label_to_name.clear() # Clear mapping for potential re-training runs\n",
    "\n",
    "    # Iterate through each person's folder in the dataset path\n",
    "    for person_name in os.listdir(data_folder_path):\n",
    "        person_folder_path = os.path.join(data_folder_path, person_name)\n",
    "\n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(person_folder_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"[INFO] Processing images for: {person_name}\")\n",
    "        # Assign a numerical label to this person\n",
    "        if person_name not in label_to_name.values():\n",
    "            label_to_name[current_label_id] = person_name\n",
    "            person_label = current_label_id\n",
    "            current_label_id += 1\n",
    "        else:\n",
    "            # This case should ideally not happen if folder names are unique identifiers\n",
    "            person_label = [id for id, name in label_to_name.items() if name == person_name][0]\n",
    "\n",
    "\n",
    "        # Iterate through images in the person's folder\n",
    "        image_count = 0\n",
    "        for image_name in os.listdir(person_folder_path):\n",
    "            image_path = os.path.join(person_folder_path, image_name)\n",
    "\n",
    "            # Read the image\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                print(f\"[WARNING] Could not read image: {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Convert to grayscale (Dlib detector and LBPH work better with grayscale)\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # Optional: Histogram Equalization can sometimes improve detection/recognition\n",
    "            # gray = cv2.equalizeHist(gray)\n",
    "\n",
    "            # Detect faces using Dlib detector\n",
    "            # Using upsampling=1 consistent with potential quality needs during training data prep\n",
    "            detected_faces = detector(gray, 1)\n",
    "\n",
    "            if len(detected_faces) == 0:\n",
    "                print(f\"[WARNING] No face detected in: {image_path} for {person_name}. Skipping.\")\n",
    "                continue\n",
    "            elif len(detected_faces) > 1:\n",
    "                 print(f\"[WARNING] Multiple faces ({len(detected_faces)}) detected in: {image_path} for {person_name}. Using the first one.\")\n",
    "\n",
    "            # Process only the first detected face for consistency\n",
    "            face_rect = detected_faces[0]\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "\n",
    "            # Ensure coordinates are valid\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            if w <= 0 or h <= 0 or x + w > gray.shape[1] or y + h > gray.shape[0]:\n",
    "                print(f\"[WARNING] Invalid face bounds detected or calculated in: {image_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Crop the face region from the grayscale image\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "\n",
    "            # Check if cropping resulted in an empty image (due to edge cases)\n",
    "            if face_roi.size == 0:\n",
    "                 print(f\"[WARNING] Empty face ROI after cropping in: {image_path}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            # Resize the face ROI to the standard size\n",
    "            try:\n",
    "                resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "            except cv2.error as e:\n",
    "                 print(f\"[WARNING] Error resizing face ROI from {image_path}: {e}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "\n",
    "            # Append the processed face and its corresponding label\n",
    "            faces.append(resized_face)\n",
    "            labels.append(person_label)\n",
    "            image_count += 1\n",
    "\n",
    "        print(f\"[INFO] Added {image_count} face images for {person_name}.\")\n",
    "\n",
    "\n",
    "    if not faces:\n",
    "        print(\"[ERROR] No faces found or processed for training. Check dataset path, image content, and warnings.\")\n",
    "        return False\n",
    "\n",
    "    if len(label_to_name) < 2:\n",
    "         print(\"[WARNING] Training requires images from at least two different people for the recognizer to be effective.\")\n",
    "         # Decide if you want to stop here or proceed with a potentially less useful model\n",
    "         # return False # Option to stop if less than 2 people\n",
    "\n",
    "    print(f\"\\n[INFO] Total faces prepared for training: {len(faces)}\")\n",
    "    print(f\"[INFO] Total unique persons (labels): {len(label_to_name)}\")\n",
    "    print(f\"[INFO] Label map: {label_to_name}\")\n",
    "    print(\"[INFO] Training LBPH model...\")\n",
    "\n",
    "    # Train the recognizer\n",
    "    # Ensure labels is a NumPy array of type int32\n",
    "    recognizer.train(faces, np.array(labels, dtype=np.int32))\n",
    "\n",
    "    print(\"[INFO] LBPH model trained successfully.\")\n",
    "    # Optional: Save the trained model and label mapping for later use\n",
    "    # recognizer.save(\"lbph_model.yml\")\n",
    "    # with open(\"label_map.txt\", \"w\") as f:\n",
    "    #  for label_id, name in label_to_name.items():\n",
    "    #     f.write(f\"{label_id}:{name}\\n\")\n",
    "    # print(\"[INFO] Model and label map saved.\")\n",
    "    return True\n",
    "\n",
    "# --- NEW: Function to Test Model on Dataset ---\n",
    "def test_model_on_dataset(data_folder_path):\n",
    "    \"\"\"\n",
    "    Tests the trained LBPH model on the images in the dataset folder\n",
    "    and calculates the success rate.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"[INFO] Starting model testing on the dataset...\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    global label_to_name, recognizer, detector, face_size, confidence_threshold\n",
    "\n",
    "    if not label_to_name:\n",
    "        print(\"[ERROR] Label map is empty. Cannot perform testing. Was the model trained?\")\n",
    "        return\n",
    "\n",
    "    # Create a reverse map for convenience (Name -> Label ID)\n",
    "    name_to_label = {name: label_id for label_id, name in label_to_name.items()}\n",
    "\n",
    "    total_tested_faces = 0\n",
    "    correct_predictions = 0\n",
    "    faces_detected_count = 0\n",
    "\n",
    "    # Iterate through each person's folder in the dataset path\n",
    "    for person_name in os.listdir(data_folder_path):\n",
    "        person_folder_path = os.path.join(data_folder_path, person_name)\n",
    "\n",
    "        if not os.path.isdir(person_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Check if this person was part of the training set\n",
    "        if person_name not in name_to_label:\n",
    "            print(f\"[WARNING] Person '{person_name}' found in dataset but not in the trained label map. Skipping testing for this person.\")\n",
    "            continue\n",
    "\n",
    "        true_label_id = name_to_label[person_name]\n",
    "        print(f\"[TESTING] Evaluating images for: {person_name} (Expected Label: {true_label_id})\")\n",
    "\n",
    "        images_in_folder = 0\n",
    "        detections_in_folder = 0\n",
    "        correct_in_folder = 0\n",
    "\n",
    "        # Iterate through images in the person's folder\n",
    "        for image_name in os.listdir(person_folder_path):\n",
    "            image_path = os.path.join(person_folder_path, image_name)\n",
    "            images_in_folder += 1\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                # Warning already given during training, maybe skip here unless verbose testing needed\n",
    "                continue\n",
    "\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # gray = cv2.equalizeHist(gray) # Apply if used in training\n",
    "\n",
    "            # Use the same detection settings as training ideally\n",
    "            detected_faces = detector(gray, 1)\n",
    "\n",
    "            if len(detected_faces) == 0:\n",
    "                 # Can log this if needed: print(f\"[TESTING-WARN] No face detected in: {image_path}\")\n",
    "                 continue # Cannot test recognition if no face is found\n",
    "\n",
    "            faces_detected_count += 1\n",
    "            detections_in_folder += 1\n",
    "\n",
    "            # Use only the first detected face for consistency with training\n",
    "            face_rect = detected_faces[0]\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            if w <= 0 or h <= 0 or x + w > gray.shape[1] or y + h > gray.shape[0]:\n",
    "                continue # Skip invalid bounds\n",
    "\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            if face_roi.size == 0:\n",
    "                 continue # Skip empty ROI\n",
    "\n",
    "            try:\n",
    "                resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "            except cv2.error:\n",
    "                continue # Skip resize errors\n",
    "\n",
    "\n",
    "            # Perform prediction\n",
    "            predicted_label_id, confidence = recognizer.predict(resized_face)\n",
    "\n",
    "            total_tested_faces += 1 # Count this face as tested for recognition\n",
    "\n",
    "            # Evaluate prediction\n",
    "            prediction_is_correct = False\n",
    "            if confidence < confidence_threshold and predicted_label_id == true_label_id:\n",
    "                correct_predictions += 1\n",
    "                correct_in_folder += 1\n",
    "                prediction_is_correct = True\n",
    "\n",
    "            # Optional: Print detailed results per image (can be very verbose)\n",
    "            # predicted_name = label_to_name.get(predicted_label_id, \"Unknown Label\")\n",
    "            # print(f\"  - {image_name}: Predicted={predicted_name}({predicted_label_id}), Confidence={confidence:.2f}, Correct={prediction_is_correct}\")\n",
    "\n",
    "        print(f\"[TESTING] Finished {person_name}: Found faces in {detections_in_folder}/{images_in_folder} images. Correctly recognized: {correct_in_folder}/{detections_in_folder}\")\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"[INFO] Dataset Testing Summary\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Total faces detected across all tested images: {faces_detected_count}\")\n",
    "    print(f\"Total detected faces subjected to recognition: {total_tested_faces}\")\n",
    "    print(f\"Total correct recognitions (within threshold): {correct_predictions}\")\n",
    "\n",
    "    if total_tested_faces > 0:\n",
    "        accuracy = (correct_predictions / total_tested_faces) * 100\n",
    "        print(f\"Recognition Success Rate: {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(\"Recognition Success Rate: N/A (No faces were successfully processed for recognition testing)\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Function for Live Face Recognition ---\n",
    "def run_live_recognition():\n",
    "    \"\"\"\n",
    "    Opens the camera, detects faces, and performs recognition using the trained model.\n",
    "    \"\"\"\n",
    "    global label_to_name # Access the global mapping\n",
    "\n",
    "    print(\"[INFO] Starting video stream for live recognition...\")\n",
    "    # Use 0 for default camera, or change if you have multiple cameras\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    time.sleep(1.0) # Allow camera sensor to warm up\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"[ERROR] Cannot open camera. Exiting.\")\n",
    "        return\n",
    "\n",
    "    prev_time = 0\n",
    "\n",
    "    while True:\n",
    "        # Read frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"[ERROR] Failed to grab frame. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # For FPS calculation\n",
    "        current_time = time.time()\n",
    "        # Avoid division by zero on the first frame\n",
    "        time_diff = current_time - prev_time\n",
    "        fps = 1 / time_diff if time_diff > 0 else 0\n",
    "        prev_time = current_time\n",
    "\n",
    "        # Convert frame to grayscale for detection\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Optional: Equalize histogram\n",
    "        # gray_frame = cv2.equalizeHist(gray_frame)\n",
    "\n",
    "        # Detect faces in the current frame\n",
    "        # Using upsampling=0 for potentially faster live performance\n",
    "        detected_faces = detector(gray_frame, 0)\n",
    "\n",
    "        # Loop over detected faces\n",
    "        for face_rect in detected_faces:\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "\n",
    "            # Ensure coordinates are valid and within frame boundaries\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            # Check width/height before calculating bottom-right corner\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue\n",
    "            # Adjust width/height if they extend beyond frame boundaries\n",
    "            w = min(w, frame.shape[1] - x)\n",
    "            h = min(h, frame.shape[0] - y)\n",
    "            # Re-check after adjustment\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Crop the face region *from the grayscale frame* for recognition\n",
    "            face_roi = gray_frame[y:y+h, x:x+w]\n",
    "\n",
    "             # Check if cropping resulted in an empty image (should be rare with checks above)\n",
    "            if face_roi.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Resize the cropped face to the standard size used for training\n",
    "            try:\n",
    "                resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "            except cv2.error:\n",
    "                continue # Skip if resize fails\n",
    "\n",
    "\n",
    "            # Perform prediction using the trained LBPH recognizer\n",
    "            label_id, confidence = recognizer.predict(resized_face)\n",
    "\n",
    "            # Get the name associated with the predicted label ID\n",
    "            # Use \"Unknown\" if confidence is too high (poor match) or label unknown\n",
    "            name = \"Unknown\" # Default\n",
    "            print(confidence)\n",
    "            if label_id in label_to_name: # Check if label exists first\n",
    "                 if confidence < confidence_threshold:\n",
    "                      name = label_to_name[label_id]\n",
    "                      display_text = f\"{name} ({confidence:.2f})\"\n",
    "                 else:\n",
    "                      # Known person, but low confidence\n",
    "                      display_text = f\"Unknown Maybe {label_to_name[label_id]}? ({confidence:.2f})\"\n",
    "                      # Or just stick with \"Unknown\":\n",
    "                      # name = \"Unknown\"\n",
    "                      # display_text = f\"{name} ({confidence:.2f})\"\n",
    "            else:\n",
    "                 # Label ID not in our map (shouldn't happen if predict works correctly)\n",
    "                 display_text = f\"Unknown Label {label_id} ({confidence:.2f})\"\n",
    "\n",
    "\n",
    "            # Draw bounding box around the face on the *original color* frame\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Put the predicted name (and confidence) text above the bounding box\n",
    "            text_y = y - 10 if y - 10 > 10 else y + h + 20 # Adjust position if too close to top\n",
    "            cv2.putText(frame, display_text, (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Display FPS on frame (optional)\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Show the resulting frame\n",
    "        cv2.imshow(\"Live Face Recognition (Press 'q' to quit)\", frame)\n",
    "\n",
    "        # Check for exit key ('q')\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    print(\"[INFO] Stopping video stream and cleaning up...\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] Application finished.\")\n",
    "\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    if not os.path.isdir(dataset_path):\n",
    "         print(f\"[ERROR] Dataset path not found or is not a directory: {dataset_path}\")\n",
    "         print(\"[INFO] Please set the 'dataset_path' variable correctly.\")\n",
    "    else:\n",
    "        # 1. Train the model\n",
    "        training_successful = train_model(dataset_path)\n",
    "\n",
    "        if training_successful:\n",
    "            # 2. Test the model (if activated)\n",
    "            if activate_test:\n",
    "                test_model_on_dataset(dataset_path)\n",
    "            else:\n",
    "                 print(\"[INFO] Skipping dataset testing as 'activate_test' is False.\")\n",
    "\n",
    "            # 3. Run live recognition (only if training was successful)\n",
    "            # Decide if you always want to run live, or maybe only if not testing, etc.\n",
    "            # Current logic: Run live recognition after training and optional testing.\n",
    "            run_live_recognition()\n",
    "        else:\n",
    "            print(\"[ERROR] Model training failed. Cannot proceed to testing or live recognition.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading face detector...\n",
      "[INFO] Loading trained LBPH model from: lbph_model.yml\n",
      "[INFO] Loading label map from: label_map.json\n",
      "[INFO] Loaded label map: {0: 'amisha', 1: 'dhanoosh', 2: 'jose', 3: 'jui', 4: 'ritvi', 5: 'siddhangana', 6: 'sparsh', 7: 'yash'}\n",
      "[INFO] Starting video stream for live recognition...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import time # For FPS calculation\n",
    "import json # To load the label map\n",
    "import argparse # To choose between testing and live modes\n",
    "\n",
    "# --- Configuration ---\n",
    "# Path to the dataset (needed for testing mode)\n",
    "dataset_path = \"png_dataset/png_dataset\" # Adjust if your path is different\n",
    "\n",
    "# Size faces were resized to during training (MUST MATCH training script)\n",
    "face_size = (100, 100)\n",
    "\n",
    "# LBPH Confidence threshold (lower values mean higher confidence)\n",
    "# Adjust this based on testing - might need values between 50 and 100\n",
    "confidence_threshold = 100\n",
    "\n",
    "# Filenames for the saved model and label map (MUST MATCH training script)\n",
    "model_filename = \"lbph_model_augmented.yml\"\n",
    "label_map_filename = \"label_map_augmented.json\"\n",
    "\n",
    "# --- Global Variables ---\n",
    "# Load Dlib's pre-trained frontal face detector\n",
    "print(\"[INFO] Loading face detector...\")\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# --- Load Model and Label Map ---\n",
    "recognizer = None\n",
    "label_to_name = None\n",
    "\n",
    "try:\n",
    "    print(f\"[INFO] Loading trained LBPH model from: {model_filename}\")\n",
    "    recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "    recognizer.read(model_filename) # Load the trained state\n",
    "\n",
    "    print(f\"[INFO] Loading label map from: {label_map_filename}\")\n",
    "    with open(label_map_filename, 'r') as f:\n",
    "        label_to_name_str_keys = json.load(f)\n",
    "        # Convert JSON string keys back to integer keys\n",
    "        label_to_name = {int(k): v for k, v in label_to_name_str_keys.items()}\n",
    "        print(f\"[INFO] Loaded label map: {label_to_name}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"[ERROR] Model file '{model_filename}' or label map '{label_map_filename}' not found.\")\n",
    "    print(\"[ERROR] Please run the train.py script first.\")\n",
    "    exit() # Exit if model/map can't be loaded\n",
    "except Exception as e:\n",
    "    print(f\"[ERROR] Error loading model or label map: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- Function to Test Model on Dataset ---\n",
    "def test_model_on_dataset(data_folder_path):\n",
    "    \"\"\"\n",
    "    Tests the loaded LBPH model on the images in the dataset folder\n",
    "    and calculates the success rate. Uses globally loaded model/map.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"[INFO] Starting model testing on the dataset...\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    if not label_to_name: # Should be loaded by now, but double-check\n",
    "        print(\"[ERROR] Label map is not loaded. Cannot perform testing.\")\n",
    "        return\n",
    "\n",
    "    if not os.path.isdir(data_folder_path):\n",
    "         print(f\"[ERROR] Dataset path for testing not found or is not a directory: {data_folder_path}\")\n",
    "         return\n",
    "\n",
    "    # Create a reverse map for convenience (Name -> Label ID)\n",
    "    name_to_label = {name: label_id for label_id, name in label_to_name.items()}\n",
    "\n",
    "    total_tested_faces = 0\n",
    "    correct_predictions = 0\n",
    "    faces_detected_count = 0\n",
    "\n",
    "    # Iterate through each person's folder in the dataset path\n",
    "    person_names = sorted(os.listdir(data_folder_path)) # Sort for consistency\n",
    "    for person_name in person_names:\n",
    "        person_folder_path = os.path.join(data_folder_path, person_name)\n",
    "\n",
    "        if not os.path.isdir(person_folder_path):\n",
    "            continue\n",
    "\n",
    "        # Check if this person was part of the training set (i.e., in the loaded map)\n",
    "        if person_name not in name_to_label:\n",
    "            print(f\"[WARNING] Person '{person_name}' found in dataset but not in the loaded label map. Skipping testing for this person.\")\n",
    "            continue\n",
    "\n",
    "        true_label_id = name_to_label[person_name]\n",
    "        print(f\"[TESTING] Evaluating images for: {person_name} (Expected Label: {true_label_id})\")\n",
    "\n",
    "        images_in_folder = 0\n",
    "        detections_in_folder = 0\n",
    "        correct_in_folder = 0\n",
    "\n",
    "        # Iterate through images in the person's folder\n",
    "        for image_name in os.listdir(person_folder_path):\n",
    "            image_path = os.path.join(person_folder_path, image_name)\n",
    "            images_in_folder += 1\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None:\n",
    "                continue # Skip unreadable images\n",
    "\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # gray = cv2.equalizeHist(gray) # Apply if used in training\n",
    "\n",
    "            # Use the same detection settings as training ideally\n",
    "            try:\n",
    "                detected_faces = detector(gray, 1)\n",
    "            except Exception as e:\n",
    "                 print(f\"[TESTING-ERROR] Face detection failed for {image_path}: {e}. Skipping.\")\n",
    "                 continue\n",
    "\n",
    "            if len(detected_faces) == 0:\n",
    "                # Can log this if needed: print(f\"[TESTING-WARN] No face detected in: {image_path}\")\n",
    "                continue # Cannot test recognition if no face is found\n",
    "\n",
    "            faces_detected_count += 1\n",
    "            detections_in_folder += 1\n",
    "\n",
    "            # Use only the first detected face for consistency with training\n",
    "            face_rect = detected_faces[0]\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            if w <= 0 or h <= 0 or x + w > gray.shape[1] or y + h > gray.shape[0]:\n",
    "                print(f\"[TESTING-WARN] Invalid face bounds in: {image_path}. Skipping.\")\n",
    "                continue # Skip invalid bounds\n",
    "\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            if face_roi.size == 0:\n",
    "                print(f\"[TESTING-WARN] Empty face ROI in: {image_path}. Skipping.\")\n",
    "                continue # Skip empty ROI\n",
    "\n",
    "            try:\n",
    "                resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "            except cv2.error:\n",
    "                 print(f\"[TESTING-WARN] Resize error for face in: {image_path}. Skipping.\")\n",
    "                 continue # Skip resize errors\n",
    "\n",
    "\n",
    "            # Perform prediction using the loaded recognizer\n",
    "            predicted_label_id, confidence = recognizer.predict(resized_face)\n",
    "\n",
    "            total_tested_faces += 1 # Count this face as tested for recognition\n",
    "\n",
    "            # Evaluate prediction\n",
    "            prediction_is_correct = False\n",
    "            # NOTE: LBPH confidence is distance - LOWER is better.\n",
    "            # We check if the prediction is BELOW the threshold AND the label matches.\n",
    "            if confidence < confidence_threshold and predicted_label_id == true_label_id:\n",
    "                correct_predictions += 1\n",
    "                correct_in_folder += 1\n",
    "                prediction_is_correct = True\n",
    "            # Handle case where prediction is correct label but confidence is too high (bad match)\n",
    "            elif predicted_label_id == true_label_id:\n",
    "                 print(f\"  - {image_name}: Correct Label ({person_name}) but HIGH confidence ({confidence:.2f}) - Not counted.\")\n",
    "            # Handle case where prediction is wrong label (confidence doesn't matter as much here for accuracy metric)\n",
    "            else:\n",
    "                predicted_name = label_to_name.get(predicted_label_id, \"Unknown Label\")\n",
    "                print(f\"  - {image_name}: Incorrectly Predicted as {predicted_name}({predicted_label_id}) with confidence {confidence:.2f}\")\n",
    "\n",
    "\n",
    "            # Optional: Print detailed results per image (can be very verbose)\n",
    "            # predicted_name_disp = label_to_name.get(predicted_label_id, f\"Unknown Label ({predicted_label_id})\")\n",
    "            # print(f\"   - {image_name}: Predicted={predicted_name_disp}, Confidence={confidence:.2f}, Correct={prediction_is_correct} (Threshold: {confidence_threshold})\")\n",
    "\n",
    "        print(f\"[TESTING] Finished {person_name}: Found faces in {detections_in_folder}/{images_in_folder} images. Correctly recognized (below threshold): {correct_in_folder}/{detections_in_folder}\")\n",
    "\n",
    "\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"[INFO] Dataset Testing Summary\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Total faces detected across all tested images: {faces_detected_count}\")\n",
    "    print(f\"Total detected faces subjected to recognition: {total_tested_faces}\")\n",
    "    print(f\"Total correct recognitions (within threshold {confidence_threshold}): {correct_predictions}\")\n",
    "\n",
    "    if total_tested_faces > 0:\n",
    "        accuracy = (correct_predictions / total_tested_faces) * 100\n",
    "        print(f\"Recognition Success Rate: {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(\"Recognition Success Rate: N/A (No faces were successfully processed for recognition testing)\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Function for Live Face Recognition ---\n",
    "def run_live_recognition():\n",
    "    \"\"\"\n",
    "    Opens the camera, detects faces, and performs recognition using the loaded model.\n",
    "    Uses globally loaded model/map.\n",
    "    \"\"\"\n",
    "    if not label_to_name: # Should be loaded, but check\n",
    "        print(\"[ERROR] Label map is not loaded. Cannot run live recognition.\")\n",
    "        return\n",
    "\n",
    "    print(\"[INFO] Starting video stream for live recognition...\")\n",
    "    # Use 0 for default camera, or change if you have multiple cameras\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    time.sleep(1.0) # Allow camera sensor to warm up\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        print(\"[ERROR] Cannot open camera. Exiting.\")\n",
    "        return\n",
    "\n",
    "    prev_time = 0\n",
    "\n",
    "    while True:\n",
    "        # Read frame from camera\n",
    "        ret, frame = cap.read()\n",
    "        if not ret or frame is None:\n",
    "            print(\"[ERROR] Failed to grab frame. Exiting.\")\n",
    "            break\n",
    "\n",
    "        # For FPS calculation\n",
    "        current_time = time.time()\n",
    "        # Avoid division by zero on the first frame\n",
    "        time_diff = current_time - prev_time\n",
    "        fps = 1 / time_diff if time_diff > 0 else 0\n",
    "        prev_time = current_time\n",
    "\n",
    "        # Convert frame to grayscale for detection\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Optional: Equalize histogram\n",
    "        # gray_frame = cv2.equalizeHist(gray_frame)\n",
    "\n",
    "        # Detect faces in the current frame\n",
    "        # Using upsampling=0 for potentially faster live performance\n",
    "        try:\n",
    "            detected_faces = detector(gray_frame, 0)\n",
    "        except Exception as e:\n",
    "            print(f\"[LIVE-ERROR] Face detection failed: {e}\")\n",
    "            detected_faces = [] # Continue with empty list\n",
    "\n",
    "\n",
    "        # Loop over detected faces\n",
    "        for face_rect in detected_faces:\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "\n",
    "            # Ensure coordinates are valid and within frame boundaries\n",
    "            x = max(0, x)\n",
    "            y = max(0, y)\n",
    "            # Check width/height before calculating bottom-right corner\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue\n",
    "            # Adjust width/height if they extend beyond frame boundaries\n",
    "            w = min(w, frame.shape[1] - x)\n",
    "            h = min(h, frame.shape[0] - y)\n",
    "            # Re-check after adjustment\n",
    "            if w <= 0 or h <= 0:\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Crop the face region *from the grayscale frame* for recognition\n",
    "            face_roi = gray_frame[y:y+h, x:x+w]\n",
    "\n",
    "            # Check if cropping resulted in an empty image (should be rare with checks above)\n",
    "            if face_roi.size == 0:\n",
    "                continue\n",
    "\n",
    "            # Resize the cropped face to the standard size used for training\n",
    "            try:\n",
    "                resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "            except cv2.error:\n",
    "                 # print(\"[LIVE-WARN] Resize failed for detected face.\") # Can be noisy\n",
    "                 continue # Skip if resize fails\n",
    "\n",
    "\n",
    "            # Perform prediction using the loaded LBPH recognizer\n",
    "            label_id, confidence = recognizer.predict(resized_face)\n",
    "\n",
    "            # Get the name associated with the predicted label ID\n",
    "            # Use \"Unknown\" if confidence is too high (poor match - above threshold) or label unknown\n",
    "            name = \"Unknown\" # Default\n",
    "            display_text = \"\"\n",
    "\n",
    "            # LBPH confidence is distance - LOWER is better.\n",
    "            if confidence < confidence_threshold:\n",
    "                if label_id in label_to_name:\n",
    "                     name = label_to_name[label_id]\n",
    "                     display_text = f\"{name} ({confidence:.2f})\"\n",
    "                else:\n",
    "                    # Recognizer predicted a label ID not in our map (should be rare if trained correctly)\n",
    "                    display_text = f\"Known? ID:{label_id} ({confidence:.2f})\"\n",
    "            else:\n",
    "                # Confidence is above the threshold (poor match)\n",
    "                # Optional: Still show potential match if label exists?\n",
    "                # if label_id in label_to_name:\n",
    "                #     display_text = f\"Maybe {label_to_name[label_id]}? ({confidence:.2f})\"\n",
    "                # else:\n",
    "                #     display_text = f\"Unknown ({confidence:.2f})\"\n",
    "                name = label_to_name[label_id]\n",
    "                display_text = f\"Unknown maybe {name}? ({confidence:.2f})\"\n",
    "\n",
    "\n",
    "            # Draw bounding box around the face on the *original color* frame\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "            # Put the predicted name (and confidence) text above the bounding box\n",
    "            text_y = y - 10 if y - 10 > 10 else y + h + 20 # Adjust position if too close to top\n",
    "            cv2.putText(frame, display_text, (x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)\n",
    "\n",
    "        # Display FPS on frame (optional)\n",
    "        cv2.putText(frame, f\"FPS: {int(fps)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "\n",
    "        # Show the resulting frame\n",
    "        cv2.imshow(\"Live Face Recognition (Press 'q' to quit)\", frame)\n",
    "\n",
    "        # Check for exit key ('q')\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    print(\"[INFO] Stopping video stream and cleaning up...\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"[INFO] Application finished.\")\n",
    "\n",
    "# --- Main Execution ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Check if model was loaded successfully before proceeding\n",
    "    if recognizer is None or label_to_name is None:\n",
    "        print(\"[ERROR] Model or label map failed to load. Exiting.\")\n",
    "    else:\n",
    "        # Run live recognition\n",
    "        run_live_recognition()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Function Definition (Modified)\n",
    "import os\n",
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm.notebook import tqdm # Import tqdm for progress bar\n",
    "\n",
    "# --- (Keep Configuration and Global Variables loading as before) ---\n",
    "# --- (Keep Model and Label Map loading as before) ---\n",
    "\n",
    "def test_model_on_dataset(data_folder_path, recognizer, detector, label_to_name, face_size, confidence_threshold):\n",
    "    \"\"\"\n",
    "    Tests the loaded LBPH model on the dataset images, collects detailed results,\n",
    "    and prints a summary.\n",
    "\n",
    "    Returns:\n",
    "        tuple: (list_true_labels, list_pred_labels, list_confidences)\n",
    "               Returns ([], [], []) if errors occur or no faces processed.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"[INFO] Starting model evaluation on the dataset...\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    # --- Input Validation ---\n",
    "    if recognizer is None: print(\"[ERROR] Recognizer not loaded.\"); return [], [], []\n",
    "    if detector is None: print(\"[ERROR] Detector not loaded.\"); return [], [], []\n",
    "    if label_to_name is None: print(\"[ERROR] Label map not loaded.\"); return [], [], []\n",
    "    if not os.path.isdir(data_folder_path):\n",
    "        print(f\"[ERROR] Dataset path not found: {data_folder_path}\"); return [], [], []\n",
    "\n",
    "    # --- Data Collection Lists ---\n",
    "    list_true_labels = []\n",
    "    list_pred_labels = []\n",
    "    list_confidences = []\n",
    "\n",
    "    # --- Helper Maps ---\n",
    "    name_to_label = {name: label_id for label_id, name in label_to_name.items()}\n",
    "    known_persons = sorted(list(name_to_label.keys())) # Get person names from map\n",
    "\n",
    "    # --- Counters for Summary ---\n",
    "    total_images_scanned = 0\n",
    "    total_faces_detected = 0\n",
    "    total_faces_processed = 0\n",
    "    correct_confident_predictions = 0 # Count predictions below threshold AND correct\n",
    "\n",
    "    # --- Iterate through known persons based on the label map ---\n",
    "    print(f\"[INFO] Evaluating {len(known_persons)} persons found in label map...\")\n",
    "    for person_name in tqdm(known_persons, desc=\"Evaluating Persons\"):\n",
    "        if person_name not in name_to_label: # Should not happen if iterating known_persons\n",
    "             print(f\"[WARN] Skipping '{person_name}' - somehow not in name_to_label map.\")\n",
    "             continue\n",
    "\n",
    "        person_folder_path = os.path.join(data_folder_path, person_name)\n",
    "        true_label_id = name_to_label[person_name]\n",
    "        # print(f\"[DEBUG] Processing {person_name} (Label: {true_label_id})\") # Optional debug\n",
    "\n",
    "        if not os.path.isdir(person_folder_path):\n",
    "            print(f\"[WARNING] Directory not found for person '{person_name}' at: {person_folder_path}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        images_in_folder = 0\n",
    "        detections_in_folder = 0\n",
    "        processed_in_folder = 0\n",
    "        correct_confident_in_folder = 0\n",
    "\n",
    "        for image_name in os.listdir(person_folder_path):\n",
    "            # Basic check for image files\n",
    "            if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "                continue\n",
    "\n",
    "            image_path = os.path.join(person_folder_path, image_name)\n",
    "            total_images_scanned += 1\n",
    "            images_in_folder += 1\n",
    "\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is None: continue # Skip unreadable\n",
    "\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            # Optional: gray = cv2.equalizeHist(gray) # Keep consistent\n",
    "\n",
    "            try:\n",
    "                detected_faces = detector(gray, 1) # Use upsampling=1 for testing\n",
    "            except Exception: continue # Skip detection errors\n",
    "\n",
    "            if not detected_faces: continue # Skip if no face detected\n",
    "\n",
    "            total_faces_detected += len(detected_faces)\n",
    "            detections_in_folder += len(detected_faces)\n",
    "\n",
    "            # Process only the first detected face\n",
    "            face_rect = detected_faces[0]\n",
    "            x, y, w, h = face_rect.left(), face_rect.top(), face_rect.width(), face_rect.height()\n",
    "            x, y = max(0, x), max(0, y)\n",
    "            if w <= 0 or h <= 0: continue\n",
    "\n",
    "            face_roi = gray[y:y+h, x:x+w]\n",
    "            if face_roi.size == 0: continue\n",
    "\n",
    "            try:\n",
    "                resized_face = cv2.resize(face_roi, face_size, interpolation=cv2.INTER_AREA)\n",
    "            except cv2.error: continue\n",
    "\n",
    "            # --- Perform prediction AND Store results ---\n",
    "            predicted_label_id, confidence = recognizer.predict(resized_face)\n",
    "            total_faces_processed += 1\n",
    "            processed_in_folder += 1\n",
    "\n",
    "            list_true_labels.append(true_label_id)\n",
    "            list_pred_labels.append(predicted_label_id)\n",
    "            list_confidences.append(confidence)\n",
    "            # ------------------------------------------\n",
    "\n",
    "            # Check for correct prediction below threshold (for summary)\n",
    "            if confidence < confidence_threshold and predicted_label_id == true_label_id:\n",
    "                correct_confident_predictions += 1\n",
    "                correct_confident_in_folder += 1\n",
    "\n",
    "        # print(f\"  - {person_name}: Processed {processed_in_folder}/{detections_in_folder} detected faces. Confident Correct: {correct_confident_in_folder}\") # Optional detail\n",
    "\n",
    "\n",
    "    # --- Final Summary ---\n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(\"[INFO] Dataset Evaluation Summary\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Total Images Scanned: {total_images_scanned}\")\n",
    "    print(f\"Total Faces Detected: {total_faces_detected}\")\n",
    "    print(f\"Total Faces Processed (Prediction Attempted): {total_faces_processed}\")\n",
    "    print(f\"Correct & Confident Recognitions (Below Threshold {confidence_threshold}): {correct_confident_predictions}\")\n",
    "\n",
    "    if total_faces_processed > 0:\n",
    "        # Accuracy calculation based ONLY on confident & correct matches vs total processed\n",
    "        # This is one way to define accuracy; others exist (e.g., raw prediction accuracy)\n",
    "        accuracy = (correct_confident_predictions / total_faces_processed) * 100\n",
    "        print(f\"Recognition Success Rate (Confident & Correct / Total Processed): {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(\"Recognition Success Rate: N/A (No faces were processed)\")\n",
    "    print(\"=\"*30 + \"\\n\")\n",
    "\n",
    "    if not list_true_labels:\n",
    "        print(\"[WARNING] No prediction results were collected during evaluation.\")\n",
    "\n",
    "    return list_true_labels, list_pred_labels, list_confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Model, detector, or label map not loaded. Cannot run evaluation.\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Run Evaluation\n",
    "\n",
    "# Ensure previous cells loaded recognizer, detector, label_to_name etc.\n",
    "if 'recognizer' in locals() and recognizer is not None and \\\n",
    "   'detector' in locals() and detector is not None and \\\n",
    "   'label_to_name' in locals() and label_to_name is not None:\n",
    "\n",
    "    # Call the evaluation function\n",
    "    true_labels, pred_labels, confidences = test_model_on_dataset(\n",
    "        dataset_path,\n",
    "        recognizer,\n",
    "        detector,\n",
    "        label_to_name,\n",
    "        face_size,\n",
    "        confidence_threshold\n",
    "    )\n",
    "\n",
    "    # Store results for later use (optional, good practice if kernel restarts)\n",
    "    # %store true_labels pred_labels confidences label_to_name known_labels_list known_names_list\n",
    "\n",
    "    print(f\"\\nCollected {len(true_labels)} evaluation results.\")\n",
    "else:\n",
    "    print(\"Error: Model, detector, or label map not loaded. Cannot run evaluation.\")\n",
    "    # Initialize empty lists to prevent errors in later cells if run independently\n",
    "    true_labels, pred_labels, confidences = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 3: Imports for Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Set plot style (optional)\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "print(\"Visualization libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 4: Confusion Matrix\n",
    "\n",
    "if not true_labels:\n",
    "    print(\"Skipping Confusion Matrix: No evaluation results available.\")\n",
    "else:\n",
    "    print(\"Generating Confusion Matrix...\")\n",
    "    known_labels_list = sorted(label_to_name.keys())\n",
    "    known_names_list = [label_to_name.get(lbl, f\"Label {lbl}\") for lbl in known_labels_list] # Use .get for safety\n",
    "\n",
    "    # Ensure labels in known_labels_list exist in true_labels or pred_labels to avoid errors\n",
    "    unique_labels_in_results = set(true_labels) | set(pred_labels)\n",
    "    valid_known_labels = [lbl for lbl in known_labels_list if lbl in unique_labels_in_results]\n",
    "    if not valid_known_labels:\n",
    "         print(\"Error: None of the known labels were found in the evaluation results.\")\n",
    "    else:\n",
    "        # Use only labels present in results for matrix calculation\n",
    "        cm = confusion_matrix(true_labels, pred_labels, labels=valid_known_labels)\n",
    "        valid_known_names = [label_to_name.get(lbl, f\"Label {lbl}\") for lbl in valid_known_labels]\n",
    "\n",
    "        plt.figure(figsize=(max(8, len(valid_known_names)*0.8), max(6, len(valid_known_names)*0.6))) # Dynamic figsize\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=valid_known_names, yticklabels=valid_known_names,\n",
    "                    annot_kws={\"size\": 10})\n",
    "        plt.xlabel('Predicted Label', fontsize=12)\n",
    "        plt.ylabel('True Label', fontsize=12)\n",
    "        plt.title('Confusion Matrix (Raw Predictions)', fontsize=14)\n",
    "        plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "        plt.yticks(rotation=0, fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('confusion_matrix.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 5: Per-Person Accuracy Bar Chart\n",
    "\n",
    "if not true_labels:\n",
    "    print(\"Skipping Per-Person Accuracy: No evaluation results available.\")\n",
    "elif 'cm' not in locals() or cm is None: # Check if cm was generated\n",
    "     print(\"Skipping Per-Person Accuracy: Confusion Matrix not available.\")\n",
    "else:\n",
    "    print(\"Generating Per-Person Accuracy...\")\n",
    "    class_counts = cm.sum(axis=1)\n",
    "    per_class_accuracy = np.zeros(len(valid_known_labels)) # Use valid labels from CM cell\n",
    "\n",
    "    for i, count in enumerate(class_counts):\n",
    "        if count > 0:\n",
    "            per_class_accuracy[i] = cm.diagonal()[i] / count\n",
    "        else:\n",
    "            per_class_accuracy[i] = np.nan\n",
    "\n",
    "    plt.figure(figsize=(max(10, len(valid_known_names)*0.6), 6)) # Dynamic figsize\n",
    "    bars = plt.bar(valid_known_names, per_class_accuracy * 100, color='skyblue')\n",
    "    plt.xlabel('Person', fontsize=12)\n",
    "    plt.ylabel('Accuracy (%) [Correct / Total True]', fontsize=12)\n",
    "    plt.title('Per-Person Recognition Accuracy (Raw Predictions)', fontsize=14)\n",
    "    plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.ylim(0, 105)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "    for bar in bars:\n",
    "         yval = bar.get_height()\n",
    "         if not np.isnan(yval):\n",
    "              plt.text(bar.get_x() + bar.get_width()/2.0, yval + 1, f'{yval:.1f}%', va='bottom', ha='center', fontsize=9)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('per_person_accuracy.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: Confidence Score Histogram\n",
    "\n",
    "if not confidences:\n",
    "    print(\"Skipping Confidence Histogram: No confidence scores available.\")\n",
    "else:\n",
    "    print(\"Generating Confidence Score Histogram...\")\n",
    "    correct_confidences = [conf for true, pred, conf in zip(true_labels, pred_labels, confidences) if true == pred]\n",
    "    incorrect_confidences = [conf for true, pred, conf in zip(true_labels, pred_labels, confidences) if true != pred]\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    max_conf = max(confidences) if confidences else 200\n",
    "    min_conf = min(confidences) if confidences else 0\n",
    "    # Adjust bins based on range, avoid too many bins if range is small\n",
    "    bin_count = min(50, max(10, int(max_conf - min_conf)))\n",
    "    bins = np.linspace(min_conf, max_conf, bin_count)\n",
    "\n",
    "    plt.hist(correct_confidences, bins=bins, alpha=0.7, label=f'Correct ({len(correct_confidences)})', color='green')\n",
    "    plt.hist(incorrect_confidences, bins=bins, alpha=0.7, label=f'Incorrect ({len(incorrect_confidences)})', color='red')\n",
    "\n",
    "    # Ensure confidence_threshold is defined (get from config or define here)\n",
    "    # confidence_threshold = 100\n",
    "    plt.axvline(confidence_threshold, color='blue', linestyle='dashed', linewidth=2, label=f'Threshold ({confidence_threshold})')\n",
    "\n",
    "    plt.xlabel('Confidence Score (Distance - Lower is Better)', fontsize=12)\n",
    "    plt.ylabel('Frequency', fontsize=12)\n",
    "    plt.title('Confidence Score Distribution (LBPH)', fontsize=14)\n",
    "    plt.legend(fontsize=10)\n",
    "    plt.xticks(fontsize=10)\n",
    "    plt.yticks(fontsize=10)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confidence_histogram.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 7: Classification Report (Text Summary)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "if not true_labels:\n",
    "    print(\"Skipping Classification Report: No evaluation results available.\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"Classification Report (Based on raw predictions)\")\n",
    "    print(\"=\"*40)\n",
    "    # Ensure labels/targets used here match those used for the CM\n",
    "    report = classification_report(true_labels, pred_labels, labels=valid_known_labels, target_names=valid_known_names, zero_division=0)\n",
    "    print(report)\n",
    "\n",
    "    # Optional: Report based on confident predictions\n",
    "    confident_true = []\n",
    "    confident_pred = []\n",
    "    for true, pred, conf in zip(true_labels, pred_labels, confidences):\n",
    "        if conf < confidence_threshold:\n",
    "             confident_true.append(true)\n",
    "             confident_pred.append(pred)\n",
    "\n",
    "    if confident_true:\n",
    "         print(\"\\n\" + \"=\"*40)\n",
    "         print(\"Classification Report (Based on predictions *below* threshold)\")\n",
    "         print(\"(Note: Metrics calculated ONLY on accepted predictions)\")\n",
    "         print(\"=\"*40)\n",
    "         # Ensure labels used here are present in the confident subset\n",
    "         confident_labels_present = sorted(list(set(confident_true) | set(confident_pred)))\n",
    "         valid_confident_labels = [lbl for lbl in valid_known_labels if lbl in confident_labels_present]\n",
    "         valid_confident_names = [label_to_name.get(lbl, f\"Label {lbl}\") for lbl in valid_confident_labels]\n",
    "\n",
    "         if valid_confident_labels:\n",
    "             report_confident = classification_report(confident_true, confident_pred, labels=valid_confident_labels, target_names=valid_confident_names, zero_division=0)\n",
    "             print(report_confident)\n",
    "         else:\n",
    "              print(\"No known labels found among confident predictions.\")\n",
    "    else:\n",
    "        print(\"\\nNo predictions were made below the confidence threshold.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image_process",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
